---
title: "Week 9 Exercises"
author: "Brad McNeney"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

We will use the `Heart` data set, split into training and 
test sets.

```{r}
uu <- url("http://faculty.marshall.usc.edu/gareth-james/ISL/Heart.csv")
Heart <- read.csv(uu,row.names=1)
Heart <- na.omit(Heart)
dim(Heart) # Train on 2/3, test on 1/3
set.seed(1)
train <- sample(1:nrow(Heart),size=2*nrow(Heart)/3,replace=FALSE)
```


### 1. Exercise with `gam()`

(a) Fit a `gam()` model for the binary response `AHD` as a function
of the categorical variables `ChestPain` and `Thal` and 
the quantitative variable `MaxHR`. In your model, 
specify a degree 4 smoothing spline for `MaxHR`.
    + Print a model summary. Note the degrees of freedom
    for the nonparametric effects ANOVA. This is the 
    difference between the df for the fitted smoothing spline
    and the df for a **linear** term. The 
    nonparametric test is for testing the non-linear component.
    In the ANOVA for the parametric effects,
    the single df test is for the **linear** effect of `MaxHR`.
    + Plot results with standard errors and comment on the fitted terms.

(b) Fit models with (i) `ChestPain` and `Thal` and a linear effect
for `MaxHR` and (ii) `ChestPain` and `Thal`.
Use the `anova()` function to compute likelihood ratio tests
for (i) the non-linear smooth of `MaxHR` and (ii)
the linear `MaxHR` term. What do you conclude?
    + Note: The tests by `anova()` are likelihood ratio
    tests. The test in part (a) is a slightly diffent 
    kind of test called a score test. We can see that the
    results of the two kinds of tests for the non-linear 
    component of `MaxHR` are nearly identical.
    
(c) Using your prefered model from part (b), predict
`AHD` on the test data with probability 
cut-off 1/2 (i.e., if the probability of AHD is 1/2 
or greater, classify as Yes)
and report the misclassification error rate.


## 2. Decision Trees

(a) Fit a classification tree to the `Heart` data, using 
`ChestPain`, `Thal`, `MaxHR` to classify `AHD`.
Plot the tree and add text to the plot. In your call
to `text()` specify  the argument `pretty=0` to 
see the categories for splits on categorical variables.


(b) Use cross-validation to select the tree size.


(c) Use the tree of best size based on part (b) to predict `AHD`, using
a probability cut-off of 1/2. Report 
the misclassification rate and compare to the 
gam/logistic regression approach in part 1.
